# ğŸ¤– RAG Chatbot dengan Self-RAG untuk Dokumen Institusional# ğŸ¤– RAG Chatbot dengan Self-RAG untuk Dokumen Institusional# Sistem Klasifikasi Berita Hoax dengan LSTM dan GloVe



Sistem Retrieval-Augmented Generation (RAG) yang canggih untuk menjawab pertanyaan tentang dokumen institusional dengan dukungan **Self-Reflective RAG** yang dapat melakukan refleksi dan kritik terhadap jawabannya sendiri.



## âœ¨ Fitur UtamaSistem Retrieval-Augmented Generation (RAG) yang canggih untuk menjawab pertanyaan tentang dokumen institusional dengan dukungan **Self-Reflective RAG** yang dapat melakukan refleksi dan kritik terhadap jawabannya sendiri.Sistem ini dirancang untuk mengumpulkan data berita dari sumber publik dan mengklasifikasikannya sebagai berita hoax atau valid menggunakan deep learning dengan LSTM dan GloVe embeddings.



- ğŸ§  **Self-Reflective RAG** - Model dapat menilai relevansi, dukungan, dan utilitas jawabannya sendiri

- ğŸ“ **Fine-tuning Support** - Latih critic model dengan LoRA untuk meningkatkan kualitas refleksi

- ğŸ‡®ğŸ‡© **IndoBERT Embeddings** - Embeddings khusus untuk bahasa Indonesia## âœ¨ Fitur Utama## Struktur Proyek

- ğŸ—„ï¸ **ChromaDB Vector Store** - Penyimpanan vektor yang cepat dan efisien

- ğŸ¦™ **Ollama Integration** - Menggunakan LLM lokal (Llama, Mistral, dll)

- ğŸŒ **Streamlit UI** - Antarmuka web yang user-friendly

- ğŸ“„ **PDF Processing** - Ekstraksi dan chunking otomatis dari dokumen PDF- ğŸ§  **Self-Reflective RAG** - Model dapat menilai relevansi, dukungan, dan utilitas jawabannya sendiri```

- ğŸ” **Multi-source Retrieval** - Mendukung filter berdasarkan lembaga/institusi

- ğŸ“ **Fine-tuning Support** - Latih critic model dengan LoRA untuk meningkatkan kualitas refleksitesis/

## ğŸ“ Struktur Proyek

- ğŸ‡®ğŸ‡© **IndoBERT Embeddings** - Embeddings khusus untuk bahasa Indonesiaâ”œâ”€â”€ data/

```

tesis/- ğŸ—„ï¸ **ChromaDB Vector Store** - Penyimpanan vektor yang cepat dan efisienâ”‚   â”œâ”€â”€ raw/              # Data mentah hasil scraping

â”œâ”€â”€ cli.py                        # ğŸ¯ Unified CLI tool (RECOMMENDED)

â”œâ”€â”€ requirements.txt              # Dependencies- ğŸ¦™ **Ollama Integration** - Menggunakan LLM lokal (Llama, Mistral, dll)â”‚   â””â”€â”€ processed/        # Data yang sudah diproses

â”œâ”€â”€ .gitignore                    # Git ignore rules

â”‚- ğŸŒ **Streamlit UI** - Antarmuka web yang user-friendlyâ”œâ”€â”€ embeddings/           # Pre-trained GloVe embeddings

â”œâ”€â”€ data_resources/               # ğŸ“š PDF documents

â”‚   â”œâ”€â”€ Lembaga Kemahasiswaan dan Alumni/- ğŸ“„ **PDF Processing** - Ekstraksi dan chunking otomatis dari dokumen PDFâ”œâ”€â”€ models/               # Model yang sudah dilatih

â”‚   â”œâ”€â”€ Lembaga Pengembangan Teknologi Informasi (LPTI)/

â”‚   â””â”€â”€ README.md- ğŸ” **Multi-source Retrieval** - Mendukung filter berdasarkan lembaga/institusiâ”œâ”€â”€ notebooks/            # Jupyter notebooks untuk eksperimen

â”‚

â”œâ”€â”€ chroma_db/                    # ğŸ—„ï¸ Vector database (auto-generated)â”œâ”€â”€ src/

â”œâ”€â”€ models/                       # ğŸ¤– Trained models (auto-generated)

â”œâ”€â”€ fine_tuning_data/             # ğŸ“Š Training datasets (auto-generated)## ğŸ“ Struktur Proyekâ”‚   â”œâ”€â”€ scraper/         # Modul web scraping

â”œâ”€â”€ logs/                         # ğŸ“ Application logs

â”‚â”‚   â”œâ”€â”€ preprocessing/   # Modul preprocessing data

â”œâ”€â”€ docs/                         # ğŸ“– Documentation

â”‚   â”œâ”€â”€ QUICK_START.md```â”‚   â””â”€â”€ model/           # Modul model LSTM

â”‚   â”œâ”€â”€ TRAINING_QUICKSTART.md    # â­ Fine-tuning guide

â”‚   â”œâ”€â”€ SELF_RAG_GUIDE.mdtesis/â”œâ”€â”€ config.py            # Konfigurasi sistem

â”‚   â”œâ”€â”€ CLI_USAGE.md

â”‚   â””â”€â”€ ...â”œâ”€â”€ cli.py                        # ğŸ¯ Unified CLI tool (RECOMMENDED)â””â”€â”€ requirements.txt     # Dependencies

â”‚

â””â”€â”€ src/                          # ğŸ’» Source codeâ”œâ”€â”€ requirements.txt              # Dependencies```

    â”œâ”€â”€ config/                   # Configuration

    â”œâ”€â”€ data_processing/          # Data pipelineâ”œâ”€â”€ .gitignore                    # Git ignore rules

    â”œâ”€â”€ embeddings/               # Embedding models

    â”œâ”€â”€ vector_db/                # Vector storageâ”‚## Setup

    â”œâ”€â”€ llm/                      # LLM integration

    â”œâ”€â”€ rag/                      # RAG pipelinesâ”œâ”€â”€ data_resources/               # ğŸ“š PDF documents

    â”œâ”€â”€ fine_tuning/              # Model training

    â”œâ”€â”€ ui/                       # User interfacesâ”‚   â”œâ”€â”€ Lembaga Kemahasiswaan dan Alumni/1. Install dependencies:

    â””â”€â”€ utils/                    # Utilities

```â”‚   â”œâ”€â”€ Lembaga Pengembangan Teknologi Informasi (LPTI)/```bash



## ğŸš€ Quick Startâ”‚   â””â”€â”€ README.mdpip install -r requirements.txt



### 1. Setup Environmentâ”‚```



```bashâ”œâ”€â”€ chroma_db/                    # ğŸ—„ï¸ Vector database (auto-generated)

# Clone repository

git clone <repository-url>â”‚2. Download NLTK data:

cd tesis

â”œâ”€â”€ models/                       # ğŸ¤– Trained models (auto-generated)```python

# Create virtual environment

python -m venv venvâ”‚   â””â”€â”€ self_rag_critic/          # Fine-tuned critic modelimport nltk

```

â”‚nltk.download('punkt')

### 2. âš ï¸ ACTIVATE VIRTUAL ENVIRONMENT (IMPORTANT!)

â”œâ”€â”€ fine_tuning_data/             # ğŸ“Š Training datasets (auto-generated)nltk.download('stopwords')

```powershell

# Windows PowerShellâ”‚   â”œâ”€â”€ train.jsonl```

.\venv\Scripts\Activate.ps1

â”‚   â”œâ”€â”€ validation.jsonl

# Windows CMD

venv\Scripts\activate.batâ”‚   â””â”€â”€ test.jsonl3. Download GloVe embeddings:



# Linux/Macâ”‚   - Download dari: https://nlp.stanford.edu/projects/glove/

source venv/bin/activate

```â”œâ”€â”€ logs/                         # ğŸ“ Application logs   - Extract file `glove.6B.100d.txt` ke folder `embeddings/`



**Ciri venv aktif**: Ada `(venv)` di prompt Anda:â”‚

```

(venv) PS D:\DEVELOPMENT\tesis>â”œâ”€â”€ docs/                         # ğŸ“– Documentation## Penggunaan

```

â”‚   â”œâ”€â”€ QUICK_START.md

### 3. Install Dependencies

â”‚   â”œâ”€â”€ SELF_RAG_GUIDE.md### 1. Mengumpulkan Data

```bash

pip install -r requirements.txtâ”‚   â”œâ”€â”€ SYSTEM_OVERVIEW.md```python

```

â”‚   â””â”€â”€ ...from src.scraper.news_scraper import NewsScraperManager

### 4. Setup Ollama

â”‚

```bash

# Install Ollama dari https://ollama.aiâ””â”€â”€ src/                          # ğŸ’» Source codescraper = NewsScraperManager()

# Download model (pilih salah satu):

ollama pull llama2    â”œâ”€â”€ config/                   # Configurationscraper.scrape_all_sources()

ollama pull mistral

ollama pull deepseek-v3.1:671b-cloud    â”‚   â”œâ”€â”€ settings.py```

```

    â”‚   â””â”€â”€ logger.py

### 5. Prepare Data

    â”œâ”€â”€ data_processing/          # Data pipeline### 2. Preprocessing Data

```bash

# Tempatkan file PDF di folder data_resources/    â”‚   â”œâ”€â”€ pdf_extractor.py```python

# Jalankan data preparation

python cli.py prepare-data    â”‚   â”œâ”€â”€ text_chunker.pyfrom src.preprocessing.text_preprocessor import TextPreprocessor

```

    â”‚   â””â”€â”€ prepare_data.py

### 6. Run Application

    â”œâ”€â”€ embeddings/               # Embedding modelspreprocessor = TextPreprocessor()

```bash

# Launch Streamlit UI    â”‚   â””â”€â”€ indobert_embeddings.pypreprocessor.process_dataset()

python cli.py run-ui

```    â”œâ”€â”€ vector_db/                # Vector storage```



Akses aplikasi di: `http://localhost:8501`    â”‚   â””â”€â”€ chroma_manager.py



## ğŸ¯ Menggunakan CLI Tool (Recommended)    â”œâ”€â”€ llm/                      # LLM integration### 3. Melatih Model



CLI tool (`cli.py`) adalah cara terbaik untuk mengelola semua operasi:    â”‚   â””â”€â”€ ollama_client.py```python



### Data Preparation    â”œâ”€â”€ rag/                      # RAG pipelinesfrom src.model.lstm_classifier import HoaxClassifier



```bash    â”‚   â”œâ”€â”€ pipeline.py           # Standard RAG

# Process semua PDFs

python cli.py prepare-data    â”‚   â””â”€â”€ self_rag_pipeline.py  # Self-RAG with criticclassifier = HoaxClassifier()



# Clear existing data dan reprocess    â”œâ”€â”€ fine_tuning/              # Model trainingclassifier.train()

python cli.py prepare-data --clear

    â”‚   â”œâ”€â”€ prepare_dataset.py```

# Process single file

python cli.py prepare-data --file path/to/document.pdf    â”‚   â”œâ”€â”€ train_critic.py

```

    â”‚   â””â”€â”€ evaluate_critic.py### 4. Prediksi

### Self-RAG Fine-tuning

    â””â”€â”€ ui/                       # User interfaces```python

```bash

# 1. Generate training dataset (dari data REAL di ChromaDB)        â””â”€â”€ app.pyfrom src.model.predictor import HoaxPredictor

python cli.py generate-dataset

```

# 2. Train critic model

python cli.py train-critic \predictor = HoaxPredictor()

  --base-model mistralai/Mistral-7B-v0.1 \

  --epochs 3 \## ğŸš€ Quick Startresult = predictor.predict("Teks berita yang akan diprediksi...")

  --batch-size 4

print(f"Prediksi: {result['label']} (Confidence: {result['confidence']:.2%})")

# 3. Evaluate model

python cli.py eval-critic \### 1. Setup Environment```

  --model-path ./models/self_rag_critic

```



**ğŸ“– Baca**: [docs/TRAINING_QUICKSTART.md](docs/TRAINING_QUICKSTART.md) untuk panduan lengkap fine-tuning```bash## Fitur



### Launch Services# Clone repository



```bashgit clone <repository-url>- âœ… Web scraping otomatis dari berbagai sumber berita

# Streamlit UI (Standard RAG)

python cli.py run-uicd tesis- âœ… Preprocessing teks bahasa Indonesia (tokenisasi, stemming, stopword removal)



# Streamlit UI (Self-RAG mode)- âœ… LSTM dengan GloVe pre-trained embeddings

python cli.py run-ui --self-rag

# Create virtual environment- âœ… Evaluasi model dengan berbagai metrik

# Custom port

python cli.py run-ui --port 8502python -m venv venv- âœ… Visualisasi hasil training

```

venv\Scripts\activate  # Windows- âœ… API untuk prediksi real-time

## ğŸ“š Dokumentasi Lengkap

# source venv/bin/activate  # Linux/Mac

- ğŸ“– [QUICK_START.md](docs/QUICK_START.md) - Panduan cepat memulai

- ğŸ“ [TRAINING_QUICKSTART.md](docs/TRAINING_QUICKSTART.md) - **Panduan fine-tuning (WAJIB BACA!)**## Arsitektur Model

- ğŸ§  [SELF_RAG_GUIDE.md](docs/SELF_RAG_GUIDE.md) - Panduan lengkap Self-RAG

- ğŸ¯ [CLI_USAGE.md](docs/CLI_USAGE.md) - Referensi lengkap CLI# Install dependencies

- ğŸ—ï¸ [SYSTEM_OVERVIEW.md](docs/SYSTEM_OVERVIEW.md) - Arsitektur sistem

- ğŸ“Š [DATASET_INFO.md](docs/DATASET_INFO.md) - Informasi datasetpip install -r requirements.txt- Input Layer: Sequence of words



## ğŸ§  Self-RAG: Apa itu?```- Embedding Layer: GloVe 100-dimensional embeddings



Self-RAG adalah teknik advanced RAG yang memungkinkan model untuk:- LSTM Layer: 128 units dengan dropout



1. **ğŸ¤” Retrieval Decision** - Memutuskan kapan perlu retrieve dokumen### 2. Setup Ollama- Dense Layer: 64 units dengan aktivasi ReLU

2. **âœ… Relevance Check** - Menilai relevansi dokumen yang di-retrieve

3. **ğŸ” Support Verification** - Memverifikasi apakah jawaban didukung oleh dokumen- Output Layer: Sigmoid activation untuk klasifikasi biner

4. **â­ Utility Evaluation** - Mengevaluasi utilitas jawaban untuk pertanyaan

```bash

Dengan fine-tuning critic model, sistem bisa belajar membuat refleksi yang lebih akurat sesuai dengan domain spesifik Anda!

# Install Ollama dari https://ollama.ai## Lisensi

## ğŸ“ Fine-tuning dengan Data Real

# Download model (pilih salah satu):

**Keunggulan**: Dataset generator sekarang menggunakan **data REAL dari dokumen Anda** (bukan random)!

ollama pull llama2Untuk keperluan penelitian/tesis.

```bash

# 1. Pastikan venv aktifollama pull mistral

.\venv\Scripts\Activate.ps1ollama pull deepseek-v3.1:671b-cloud

```

# 2. Prepare data dulu

python cli.py prepare-data### 3. Prepare Data



# 3. Generate dataset dari dokumen real```bash

python cli.py generate-dataset# Tempatkan file PDF di folder data_resources/

# Jalankan data preparation

# 4. Train (gunakan model open-source)python cli.py prepare-data

python cli.py train-critic \```

  --base-model mistralai/Mistral-7B-v0.1 \

  --epochs 3### 4. Run Application

```

```bash

**ğŸ“– PENTING**: Baca [docs/TRAINING_QUICKSTART.md](docs/TRAINING_QUICKSTART.md) sebelum fine-tuning!# Launch Streamlit UI

python cli.py run-ui

## âš ï¸ Common Issues & Solutions```



### Issue 1: "ModuleNotFoundError: No module named 'peft'"Akses aplikasi di: `http://localhost:8501`



**Penyebab**: Virtual environment tidak aktif## ğŸ¯ Menggunakan CLI Tool (Recommended)



**Solusi**:CLI tool (`cli.py`) adalah cara terbaik untuk mengelola semua operasi:

```bash

.\venv\Scripts\Activate.ps1### Data Preparation

python cli.py train-critic

``````bash

# Process semua PDFs

### Issue 2: "GatedRepoError: Cannot access gated repo"python cli.py prepare-data



**Penyebab**: Model Llama-2 memerlukan authentication# Clear existing data dan reprocess

python cli.py prepare-data --clear

**Solusi**: Gunakan model open-source

```bash# Process single file

python cli.py train-critic --base-model mistralai/Mistral-7B-v0.1python cli.py prepare-data --file path/to/document.pdf

``````



### Issue 3: "CUDA Out of Memory"### Self-RAG Fine-tuning



**Solusi**: Reduce batch size```bash

```bash# 1. Generate training dataset

python cli.py train-critic --batch-size 1python cli.py generate-dataset \

```  --output-dir ./fine_tuning_data \

  --num-retrieval 200 \

## ğŸ”§ Configuration  --num-relevance 200 \

  --num-support 100 \

Edit `src/config/settings.py` untuk mengubah:  --num-utility 100



- Model Ollama yang digunakan# 2. Train critic model

- Chunk size dan overlappython cli.py train-critic \

- Top-k retrieval  --base-model meta-llama/Llama-2-7b-hf \

- Temperature dan parameter LLM  --output-dir ./models/self_rag_critic \

- Path ke data dan models  --epochs 3 \

  --batch-size 4 \

## ğŸ“Š Monitoring & Logging  --use-wandb



- Logs tersimpan di folder `logs/`# 3. Evaluate model

- Training metrics tersimpan di `models/*/`python cli.py eval-critic \

- Evaluation results di `models/evaluation_results.json`  --model-path ./models/self_rag_critic \

  --test-data ./fine_tuning_data/test.jsonl

## ğŸ¤ Contributing```



Proyek ini untuk keperluan penelitian/tesis. Saran dan feedback sangat diterima!### Launch Services



## ğŸ“ Lisensi```bash

# Streamlit UI (Standard RAG)

Untuk keperluan penelitian/tesis.python cli.py run-ui



---# Streamlit UI (Self-RAG mode)

python cli.py run-ui --self-rag

**â­ Ingat**: SELALU aktifkan virtual environment sebelum menjalankan command! 

# Custom port

```bashpython cli.py run-ui --port 8502

.\venv\Scripts\Activate.ps1  # Windows

```# FastAPI server (jika sudah dibuat)

python cli.py run-api --port 8000
```

## ğŸ“š Dokumentasi Lengkap

- ğŸ“– [QUICK_START.md](docs/QUICK_START.md) - Panduan cepat memulai
- ğŸ§  [SELF_RAG_GUIDE.md](docs/SELF_RAG_GUIDE.md) - Panduan lengkap Self-RAG
- ğŸ—ï¸ [SYSTEM_OVERVIEW.md](docs/SYSTEM_OVERVIEW.md) - Arsitektur sistem
- ğŸ“Š [DATASET_INFO.md](docs/DATASET_INFO.md) - Informasi dataset

## ğŸ§  Self-RAG: Apa itu?

Self-RAG adalah teknik advanced RAG yang memungkinkan model untuk:

1. **ğŸ¤” Retrieval Decision** - Memutuskan kapan perlu retrieve dokumen
2. **âœ… Relevance Check** - Menilai relevansi dokumen yang di-retrieve
3. **ğŸ” Support Verification** - Memverifikasi apakah jawaban didukung oleh dokumen
4. **â­ Utility Evaluation** - Mengevaluasi utilitas jawaban untuk pertanyaan

Dengan fine-tuning critic model, sistem bisa belajar membuat refleksi yang lebih akurat sesuai dengan domain spesifik Anda!

## ğŸ”§ Configuration

Edit `src/config/settings.py` untuk mengubah:

- Model Ollama yang digunakan
- Chunk size dan overlap
- Top-k retrieval
- Temperature dan parameter LLM
- Path ke data dan models

## ğŸ“Š Monitoring & Logging

- Logs tersimpan di folder `logs/`
- Training metrics tersimpan di `models/*/`
- Evaluation results di `models/evaluation_results.json`

## ğŸ¤ Contributing

Proyek ini untuk keperluan penelitian/tesis. Saran dan feedback sangat diterima!

## ğŸ“ Lisensi

Untuk keperluan penelitian/tesis.
#   s e l f - R A G  
 